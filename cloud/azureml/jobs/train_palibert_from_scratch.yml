$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command
description: Train a Masked Language Model using HuggingFace

compute: azureml:v100-lp

inputs:
  # training inputs
  train_file:
    type: uri_file
    path: azureml:bpe_train_data@latest # register using data/bpe_train.yml
  model_config:
    type: uri_folder
    path: ../../../models/palibert-base/config/

  # training params
  learning_rate: 1e-5
  epochs: 50
  batch_size: 16

outputs:
  checkpoints:
    type: uri_folder

code: ../../../scripts/

command: >-
  python ./run_mlm.py 
  --model_type albert-base-v2 
  --config_name ${{inputs.model_config}} 
  --tokenizer_name ${{inputs.model_config}} 
  --train_file ${{inputs.train_file}} 
  --line_by_line 
  --do_train 
  --do_eval 
  --validation_file ${{inputs.train_file}} 
  --evaluation_strategy steps 
  --num_train_epochs ${{inputs.epochs}} 
  --learning_rate ${{inputs.learning_rate}} 
  --per_gpu_train_batch_size ${{inputs.batch_size}} 
  --gradient_accumulation_steps 4 
  --max_seq_length 512 
  --output_dir ${{outputs.checkpoints}} 
  --save_total_limit 10 
  --save_steps 5000 
  --logging_steps 5000 
  --seed 42 

environment: azureml:palibert@latest

environment_variables:
    PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:512"
